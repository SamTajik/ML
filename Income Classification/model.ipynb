{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1710b2-779e-41f9-b5a6-abe1eeb71572",
   "metadata": {},
   "source": [
    "# model trainig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db8dfb-6255-4cdc-83df-9c95005a5f27",
   "metadata": {},
   "source": [
    "First, we import pandas and some objects and functions from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b7f4cbe-ff87-4dd9-97f3-1651606d1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce995b0-49c4-4026-932a-94e44a666903",
   "metadata": {},
   "source": [
    "Next, we read the prepared data and save it in a pandas dataframe named \n",
    "<code>df</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6520ba4-cb3f-458a-b8b8-56c7ed9967df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>workclass_?</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_Other-relative</th>\n",
       "      <th>relationship_Own-child</th>\n",
       "      <th>relationship_Unmarried</th>\n",
       "      <th>relationship_Wife</th>\n",
       "      <th>race_Amer-Indian-Eskimo</th>\n",
       "      <th>race_Asian-Pac-Islander</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_White</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>103497</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48702</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48703</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48704</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48705</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48706</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48707 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
       "0       25  226802                7             0             0   \n",
       "1       38   89814                9             0             0   \n",
       "2       28  336951               12             0             0   \n",
       "3       44  160323               10          7688             0   \n",
       "4       18  103497               10             0             0   \n",
       "...    ...     ...              ...           ...           ...   \n",
       "48702   27  257302               12             0             0   \n",
       "48703   40  154374                9             0             0   \n",
       "48704   58  151910                9             0             0   \n",
       "48705   22  201490                9             0             0   \n",
       "48706   52  287927                9         15024             0   \n",
       "\n",
       "       hours-per-week  income  workclass_?  workclass_Federal-gov  \\\n",
       "0                  40    True        False                  False   \n",
       "1                  50    True        False                  False   \n",
       "2                  40    True        False                  False   \n",
       "3                  40    True        False                  False   \n",
       "4                  30    True         True                  False   \n",
       "...               ...     ...          ...                    ...   \n",
       "48702              38    True        False                  False   \n",
       "48703              40    True        False                  False   \n",
       "48704              40    True        False                  False   \n",
       "48705              20    True        False                  False   \n",
       "48706              40    True        False                  False   \n",
       "\n",
       "       workclass_Local-gov  ...  relationship_Other-relative  \\\n",
       "0                    False  ...                        False   \n",
       "1                    False  ...                        False   \n",
       "2                     True  ...                        False   \n",
       "3                    False  ...                        False   \n",
       "4                    False  ...                        False   \n",
       "...                    ...  ...                          ...   \n",
       "48702                False  ...                        False   \n",
       "48703                False  ...                        False   \n",
       "48704                False  ...                        False   \n",
       "48705                False  ...                        False   \n",
       "48706                False  ...                        False   \n",
       "\n",
       "       relationship_Own-child  relationship_Unmarried  relationship_Wife  \\\n",
       "0                        True                   False              False   \n",
       "1                       False                   False              False   \n",
       "2                       False                   False              False   \n",
       "3                       False                   False              False   \n",
       "4                        True                   False              False   \n",
       "...                       ...                     ...                ...   \n",
       "48702                   False                   False               True   \n",
       "48703                   False                   False              False   \n",
       "48704                   False                    True              False   \n",
       "48705                    True                   False              False   \n",
       "48706                   False                   False               True   \n",
       "\n",
       "       race_Amer-Indian-Eskimo  race_Asian-Pac-Islander  race_Black  \\\n",
       "0                        False                    False        True   \n",
       "1                        False                    False       False   \n",
       "2                        False                    False       False   \n",
       "3                        False                    False        True   \n",
       "4                        False                    False       False   \n",
       "...                        ...                      ...         ...   \n",
       "48702                    False                    False       False   \n",
       "48703                    False                    False       False   \n",
       "48704                    False                    False       False   \n",
       "48705                    False                    False       False   \n",
       "48706                    False                    False       False   \n",
       "\n",
       "       race_Other  race_White  gender_Male  \n",
       "0           False       False         True  \n",
       "1           False        True         True  \n",
       "2           False        True         True  \n",
       "3           False       False         True  \n",
       "4           False        True        False  \n",
       "...           ...         ...          ...  \n",
       "48702       False        True        False  \n",
       "48703       False        True         True  \n",
       "48704       False        True        False  \n",
       "48705       False        True         True  \n",
       "48706       False        True        False  \n",
       "\n",
       "[48707 rows x 46 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('adult_income_prepared.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9232639-1da1-4836-8036-89cf6359069a",
   "metadata": {},
   "source": [
    "After defining X and y we need three sets of data:\n",
    "<ol>\n",
    "    <li>A trainig set to fit our model</li>\n",
    "    <li>A validation set to find best hyper parameters for our model</li>\n",
    "    <li>A test set to evaluate our model performance</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f57c31da-efc9-42c8-87e5-62f967ae468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining X and y\n",
    "#splitting train set, validation set and test set\n",
    "\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test ,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685308e-536e-4e93-afc9-09cc85ab5e4b",
   "metadata": {},
   "source": [
    "We should make sure there is no disparity in percentage of ones between the three y sets.\n",
    "$$\n",
    "    \\mathrm{percentage\\ of\\ ones} = \n",
    "    \\frac{\\mathrm{number\\ of\\ ones}}{\\mathrm{total\\ number\\ of\\ samples}}\n",
    "$$\n",
    "$$\n",
    "    \\mathrm{average} =\n",
    "    \\frac{1 \\times \\mathrm{number\\ of\\ ones} + 0 \\times \\mathrm{number\\ of\\ zeroes}}\n",
    "    {\\mathrm{total\\ number\\ of\\ samples}}\n",
    "$$\n",
    "\n",
    "As we can see percantage of ones in a binary array is equal to average value of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "176b778f-e603-403a-bbcc-caf0cb37ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2427194421657096\n",
      "0.2365065800717826\n",
      "0.24405250205086138\n"
     ]
    }
   ],
   "source": [
    "#checking to see if distribution in sets are fair\n",
    "\n",
    "print(y_val.mean())\n",
    "print(y_train.mean())\n",
    "print(y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047718e3-e257-474f-ac1c-0e61ac384585",
   "metadata": {},
   "source": [
    "We have to scale our X sets. Here we use standard scaler. We could also use min max scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "206d8826-0d95-4920-80b0-628600e2785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c54e68-effe-4111-bf01-3a0e9b8688d4",
   "metadata": {},
   "source": [
    "If we want a high performance model we have to find the best hyper parameters. \n",
    "To do that we use train set to fit models with different hyper parameters and validation set to \n",
    "evaluate performance of these models. Finally with comparing the results we can find best hyper parameters.\n",
    "\n",
    "As our data is unbalanced (number of ones in y is a third of number of zeroes), accuracy score is not a good metric for \n",
    "evaluating our model. We shall use recall score, precision score and f1 score for evaluation. Of course depending on \n",
    "our objective the importance of these metrics can vary. For example if identifing the most ones is of greater importance to us we shall put greater importance to recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c065d9fa-02c1-4cf1-90b9-a7d6eca0ee1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".jp-Cell-outputArea {\n",
       "    overflow-y: auto;\n",
       "    max-height: 400px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making our output a scroolable box with limited height\n",
    "# just something about visualisation\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<style>\n",
    ".jp-Cell-outputArea {\n",
    "    overflow-y: auto;\n",
    "    max-height: 400px;\n",
    "}\n",
    "</style>\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169ec9d-c7a8-4076-a094-3a60cbec7ed1",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "\n",
    "In the cell below we use logistic regresion models and evaluate their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1fdd5-54ad-4179-a8db-01961cadb161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   -----------------\n",
      "C: 0.01, max_iter: 100, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.562, recall: 0.851, f1:0.677\n",
      "2   -----------------\n",
      "C: 0.01, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.562, recall: 0.851, f1:0.677\n",
      "3   -----------------\n",
      "C: 0.01, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.562, recall: 0.851, f1:0.677\n",
      "4   -----------------\n",
      "C: 0.1, max_iter: 100, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.569, recall: 0.840, f1:0.678\n",
      "5   -----------------\n",
      "C: 0.1, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.569, recall: 0.840, f1:0.678\n",
      "6   -----------------\n",
      "C: 0.1, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.569, recall: 0.840, f1:0.678\n",
      "7   -----------------\n",
      "C: 1, max_iter: 100, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "8   -----------------\n",
      "C: 1, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "9   -----------------\n",
      "C: 1, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "10   -----------------\n",
      "C: 10, max_iter: 100, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "11   -----------------\n",
      "C: 10, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "12   -----------------\n",
      "C: 10, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "13   -----------------\n",
      "C: 0.01, max_iter: 100, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.563, recall: 0.843, f1:0.675\n",
      "14   -----------------\n",
      "C: 0.01, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.563, recall: 0.843, f1:0.675\n",
      "15   -----------------\n",
      "C: 0.01, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.563, recall: 0.843, f1:0.675\n",
      "16   -----------------\n",
      "C: 0.1, max_iter: 100, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.569, recall: 0.840, f1:0.679\n",
      "17   -----------------\n",
      "C: 0.1, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.569, recall: 0.840, f1:0.679\n",
      "18   -----------------\n",
      "C: 0.1, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.569, recall: 0.840, f1:0.679\n",
      "19   -----------------\n",
      "C: 1, max_iter: 100, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "20   -----------------\n",
      "C: 1, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "21   -----------------\n",
      "C: 1, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "22   -----------------\n",
      "C: 10, max_iter: 100, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "23   -----------------\n",
      "C: 10, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "24   -----------------\n",
      "C: 10, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "25   -----------------\n",
      "C: 0.01, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.564, recall: 0.838, f1:0.674\n",
      "26   -----------------\n",
      "C: 0.01, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.564, recall: 0.838, f1:0.674\n",
      "27   -----------------\n",
      "C: 0.01, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.564, recall: 0.838, f1:0.674\n",
      "28   -----------------\n",
      "C: 0.1, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.570, recall: 0.840, f1:0.679\n",
      "29   -----------------\n",
      "C: 0.1, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.570, recall: 0.840, f1:0.679\n",
      "30   -----------------\n",
      "C: 0.1, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.570, recall: 0.840, f1:0.679\n",
      "31   -----------------\n",
      "C: 1, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "32   -----------------\n",
      "C: 1, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "33   -----------------\n",
      "C: 1, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.571, recall: 0.840, f1:0.680\n",
      "34   -----------------\n",
      "C: 10, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.572, recall: 0.840, f1:0.680\n",
      "35   -----------------\n",
      "C: 10, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.572, recall: 0.840, f1:0.680\n",
      "36   -----------------\n",
      "C: 10, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: balanced\n",
      "precision: 0.572, recall: 0.840, f1:0.680\n",
      "37   -----------------\n",
      "C: 0.01, max_iter: 100, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.732, recall: 0.571, f1:0.641\n",
      "38   -----------------\n",
      "C: 0.01, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.732, recall: 0.571, f1:0.641\n",
      "39   -----------------\n",
      "C: 0.01, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.732, recall: 0.571, f1:0.641\n",
      "40   -----------------\n",
      "C: 0.1, max_iter: 100, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.589, f1:0.651\n",
      "41   -----------------\n",
      "C: 0.1, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.589, f1:0.651\n",
      "42   -----------------\n",
      "C: 0.1, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.589, f1:0.651\n",
      "43   -----------------\n",
      "C: 1, max_iter: 100, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "44   -----------------\n",
      "C: 1, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "45   -----------------\n",
      "C: 1, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "46   -----------------\n",
      "C: 10, max_iter: 100, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "47   -----------------\n",
      "C: 10, max_iter: 1000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "48   -----------------\n",
      "C: 10, max_iter: 10000, solver: liblinear, penalty: l1, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "49   -----------------\n",
      "C: 0.01, max_iter: 100, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.724, recall: 0.592, f1:0.651\n",
      "50   -----------------\n",
      "C: 0.01, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.724, recall: 0.592, f1:0.651\n",
      "51   -----------------\n",
      "C: 0.01, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.724, recall: 0.592, f1:0.651\n",
      "52   -----------------\n",
      "C: 0.1, max_iter: 100, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "53   -----------------\n",
      "C: 0.1, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "54   -----------------\n",
      "C: 0.1, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "55   -----------------\n",
      "C: 1, max_iter: 100, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "56   -----------------\n",
      "C: 1, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "57   -----------------\n",
      "C: 1, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "58   -----------------\n",
      "C: 10, max_iter: 100, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "59   -----------------\n",
      "C: 10, max_iter: 1000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "60   -----------------\n",
      "C: 10, max_iter: 10000, solver: liblinear, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.592, f1:0.653\n",
      "61   -----------------\n",
      "C: 0.01, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.580, f1:0.646\n",
      "62   -----------------\n",
      "C: 0.01, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.580, f1:0.646\n",
      "63   -----------------\n",
      "C: 0.01, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.580, f1:0.646\n",
      "64   -----------------\n",
      "C: 0.1, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "65   -----------------\n",
      "C: 0.1, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "66   -----------------\n",
      "C: 0.1, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "67   -----------------\n",
      "C: 1, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "68   -----------------\n",
      "C: 1, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "69   -----------------\n",
      "C: 1, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "70   -----------------\n",
      "C: 10, max_iter: 100, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "71   -----------------\n",
      "C: 10, max_iter: 1000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n",
      "72   -----------------\n",
      "C: 10, max_iter: 10000, solver: lbfgs, penalty: l2, class_weight: None\n",
      "precision: 0.727, recall: 0.591, f1:0.652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "Cs = [0.01, 0.1, 1, 10]\n",
    "max_iters = [100, 1000, 10000]\n",
    "solvers = ['liblinear', 'lbfgs']\n",
    "penalties = ['l1', 'l2']\n",
    "class_weights = ['balanced', None]\n",
    "counter = 1\n",
    "\n",
    "for class_weight in class_weights:\n",
    "    for penalty in penalties:\n",
    "        for solver in solvers:\n",
    "            for C in Cs:\n",
    "                for max_iter in max_iters:\n",
    "\n",
    "                    if (penalty=='l1' and solver=='lbfgs'):\n",
    "                        continue\n",
    "                        \n",
    "                    model = LogisticRegression(\n",
    "                        penalty=penalty,\n",
    "                        C=C, \n",
    "                        solver=solver,\n",
    "                        max_iter=max_iter,\n",
    "                        class_weight=class_weight,\n",
    "                        random_state=42\n",
    "                    )\n",
    "        \n",
    "                    model.fit(X_train, y_train)\n",
    "                    logisticreg_pred = model.predict(X_val)\n",
    "                    f1 = f1_score(y_val,  logisticreg_pred)\n",
    "\n",
    "                    print(f\"{counter}   -----------------\")\n",
    "                    print(\n",
    "                        f\"C: {C}, \"\n",
    "                        f\"max_iter: {max_iter}, \"\n",
    "                        f\"solver: {solver}, \"\n",
    "                        f\"penalty: {penalty}, \"\n",
    "                        f\"class_weight: {class_weight}\"\n",
    "                    )\n",
    "                    print(f\"f1_score:{f1:.3f}\")\n",
    "                    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d32d3-cc09-4462-9dc1-1017622fb5ec",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "\n",
    "In the cell below we use SVM models and evaluate their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3130b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   -----------------\n",
      "kernel: linear, class_weight: balanced\n",
      "precision: 0.546, recall: 0.854, f1:0.666\n",
      "2   -----------------\n",
      "kernel: rbf, class_weight: balanced\n",
      "precision: 0.542, recall: 0.829, f1:0.655\n",
      "3   -----------------\n",
      "kernel: linear, class_weight: None\n",
      "precision: 0.741, recall: 0.585, f1:0.654\n",
      "4   -----------------\n",
      "kernel: rbf, class_weight: None\n",
      "precision: 0.744, recall: 0.549, f1:0.632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['linear', 'rbf']\n",
    "class_weights = ['balanced', None]\n",
    "counter = 1\n",
    "\n",
    "for class_weight in class_weights:\n",
    "    for kernel in kernels:                       \n",
    "        model = SVC(\n",
    "            kernel=kernel,\n",
    "            C=0.1,\n",
    "            class_weight=class_weight,\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        svm_pred = model.predict(X_val)\n",
    "        f1 = f1_score(y_val,  svm_pred)\n",
    "\n",
    "        print(f\"{counter}   -----------------\")\n",
    "        print(\n",
    "            f\"kernel: {kernel}, \"\n",
    "            f\"class_weight: {class_weight}\"\n",
    "        )\n",
    "        print(f\"f1_score:{f1:.3f}\")\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bd0b5",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfa27365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score:0.714\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                               scale_pos_weight=3, #number of zeroes/number of ones\n",
    "                               random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_val)\n",
    "f1 = f1_score(y_val, xgb_pred)\n",
    "print(f\"f1-score:{f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afc7e27-8849-4b61-90a7-74fdd06c71b4",
   "metadata": {},
   "source": [
    "In this problem our goal is to maximize f1 score. The highest f1 score belongs to XGboost model and the difference is substantial. Therefore it will bo our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79779c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejoining trainig set and validation set now that validation set has served it's purpose\n",
    "\n",
    "X_train = np.concatenate([X_train, X_val], axis=0)\n",
    "y_train = np.concatenate([y_train, y_val], axis=0)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9462a99d-6e4d-441a-b905-26b00e7b49e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final model f1_score: 0.717\n"
     ]
    }
   ],
   "source": [
    "# making a xgboost model(final choice)\n",
    "model = xgb_model = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                               scale_pos_weight=3, #number of zeroes/number of ones\n",
    "                               random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"final model f1_score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba3ad0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547e2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
